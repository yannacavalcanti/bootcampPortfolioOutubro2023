{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootcamp: Construa seu Portfólio em Ciência de Dados\n",
    "\n",
    "**Autora**: Yanna Cavalcanti\n",
    "\n",
    "**Data**: Junho 2023\n",
    "\n",
    "---\n",
    "\n",
    "## Projeto: Detecção dos principais drivers de churn para retenção de clientes\n",
    "\n",
    "#### Indústria e mercado\n",
    "\n",
    "Esse projeto se enquadra na indústria de telecomunicações. Empresas de telecomunicações conhecidas no setor incluem **Vivo**, **Tim** e **Claro**.\n",
    "\n",
    "#### Contexto\n",
    "\n",
    "Você foi contratado como cientista de dados por uma empresa de telecomunicações que enfrenta um problema crescente de churn. A empresa deseja reduzir a taxa de cancelamento de seus clientes, aumentando a satisfação e a fidelidade dos mesmos.  Atualmente, a empresa não possui nenhum modelo ou estratégia específica para prever o churn e tomar ações preventivas.\n",
    "\n",
    "![churn1](https://miro.medium.com/v2/resize:fit:400/0*I9LmVPMFSuDwHumR)\n",
    "\n",
    "#### Objetivo\n",
    "\n",
    "Seu objetivo é identificar os principais drivers de churn para a criação de estratégias de retenção. Você fará isso a partir de uma análise exploratória e do desenvolvimento de um modelo de aprendizado de máquina que seja capaz de prever quais clientes estão mais propensos a cancelar o serviço (churn), com base no conjunto de atributos relacionados ao comportamento e no uso dos serviços de telecomunicações. A identificação dos principais drivers acionáveis e como eles interagem entre si vai permitir à empresa tomar ações preventivas, oferecendo promoções, descontos ou outros incentivos para mantê-los satisfeitos e evitar o churn.\n",
    "\n",
    "![image.png](https://miro.medium.com/v2/resize:fit:800/0*yikht5caA9CDdVEE.jpg)\n",
    "\n",
    "Você também precisa propor estratégias de redução de churn a partir dos drivers selecionados e demonstrar o **POTENCIAL** de redução da taxa de churn após a implementação de cada uma delas. Para isso, você vai seguir os seguintes passos após descobrir os principais drivers de churn:\n",
    "* 1) Criar de 2 a 4 estratégias para redução do churn, como ofertas, descontos, bônus, etc.\n",
    "* 2) Calcular a propensão a churn nos dados de teste com o modelo que você criou.\n",
    "* 3) **ALTERAR** a feature ou features dos dados de teste que seriam **AFETADAS** pela estratégia que você criou no ponto 1.\n",
    "* 4) Calcular a propensão ao churn novamente com essa base alterada e comparar com o que você tinha antes para entender quantos % do churn sua estratégia tem o potencial de reduzir.\n",
    "\n",
    "Lembrando que isso é uma **simulação**, pois não temos como avaliar na vida real o quanto as estratégias estão funcionando. Nossa simulação de POTENCIAL inclui o pressuposto de que **todos os clientes aceitaram a oferta proposta a eles**. Num cenário real, você faria o acompanhamento ao longo do tempo com métricas de performance para avaliar a redução da taxa de churn.\n",
    "\n",
    "**Dica**: *Keep it simple* ou simplifique! Não tente criar estratégias mirabolantes demais. Tente manter em torno de uma estratégia por driver e evite fazer muitas combinações para não se confundir.\n",
    "\n",
    "\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "- **Dataset Source:** [Kaggle](https://www.kaggle.com/datasets/yeanzc/telco-customer-churn-ibm-dataset)\n",
    "\n",
    "- **Dataset Description**:\n",
    "\n",
    "Cada registro no banco de dados descreve um cliente da empresa de telecomunicações. Os dados foram coletados ao longo de um período de tempo e incluem informações sobre o comportamento e o uso dos serviços, bem como algumas características demográficas dos clientes. Os atributos são definidos da seguinte forma:\n",
    "\n",
    "- CustomerID: um ID único que identifica cada cliente\n",
    "- Count: um valor usado em relatórios ou painéis para somar o número de clientes em um conjunto filtrado (não é relevante)\n",
    "- Gender: gênero do cliente\n",
    "- Country: o país de residência principal do cliente\n",
    "- State: o estado de residência principal do cliente\n",
    "- City: a cidade de residência principal do cliente\n",
    "- Zip Code: O código postal da residência principal do cliente.\n",
    "- Lat Long: A combinação da latitude e longitude da residência principal do cliente\n",
    "- Latitude: A latitude da residência principal do cliente\n",
    "- Longitude: A longitude da residência principal do cliente\n",
    "- Senior Citizen: indica se o cliente é idoso ou não\n",
    "- Partner: indica se o cliente possui um parceiro (cônjuge)\n",
    "- Dependents: indica se o cliente possui dependentes\n",
    "- Tenure Months: quantidade de meses que o cliente está com a empresa\n",
    "- Phone Service: indica se o cliente possui serviço de telefone\n",
    "- Multiple Lines: indica se o cliente possui múltiplas linhas de telefone\n",
    "- Internet Service: tipo de serviço de internet do cliente (DSL, Fiber optic ou No)\n",
    "- Online Security: indica se o cliente possui serviço de segurança online\n",
    "- Online Backup: indica se o cliente possui serviço de backup online\n",
    "- Device Protection: indica se o cliente possui serviço de proteção de dispositivos\n",
    "- Tech Support: indica se o cliente possui serviço de suporte técnico\n",
    "- Streaming TV: indica se o cliente possui serviço de streaming de TV\n",
    "- Streaming Movies: indica se o cliente possui serviço de streaming de filmes\n",
    "- Contract: tipo de contrato do cliente (Month-to-month, One year ou Two year)\n",
    "- Paperless Billing: indica se o cliente recebe a fatura em papel ou eletronicamente\n",
    "- Payment Method: método de pagamento do cliente (eletrônico, cheque, etc)\n",
    "- Monthly Charges: valor mensal cobrado do cliente\n",
    "- Total Charges: valor total cobrado do cliente\n",
    "- Churn Label: Yes = o cliente saiu da empresa neste trimestre. No = o cliente permaneceu na empresa. Diretamente relacionado ao Churn Value\n",
    "- Churn Value: 1 = o cliente saiu da empresa neste trimestre. 0 = o cliente permaneceu na empresa. Diretamente relacionado ao Churn Label.\n",
    "- Churn Score: um valor de 0 a 100 calculado usando a ferramenta preditiva IBM SPSS Modeler. O modelo incorpora vários fatores conhecidos por causar churn. Esse score não será usado nesse case.\n",
    "- CLTV: Valor Vitalício do Cliente ou *Lifetime value*. Um CLTV previsto é calculado usando fórmulas corporativas e dados existentes. Quanto maior o valor, mais valioso é o cliente. Clientes de alto valor devem ser monitorados para identificar churn.\n",
    "- Churn Reason: A razão específica do cliente para deixar a empresa. Diretamente relacionado à categoria de churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA e pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos checar se o dataset está na pasta importando a biblioteca \"os\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:46.799542Z",
     "iopub.status.busy": "2023-07-31T22:27:46.799089Z",
     "iopub.status.idle": "2023-07-31T22:27:46.845856Z",
     "shell.execute_reply": "2023-07-31T22:27:46.844715Z",
     "shell.execute_reply.started": "2023-07-31T22:27:46.799507Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "    \n",
    "os.listdir(\"../input/telco-customer-churn-ibm-dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos ler o dataset com \"pandas\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:46.847922Z",
     "iopub.status.busy": "2023-07-31T22:27:46.847465Z",
     "iopub.status.idle": "2023-07-31T22:27:50.885200Z",
     "shell.execute_reply": "2023-07-31T22:27:50.884011Z",
     "shell.execute_reply.started": "2023-07-31T22:27:46.847895Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Carregar o conjunto de dados\n",
    "data = pd.read_excel(\"../input/telco-customer-churn-ibm-dataset/Telco_customer_churn.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando as primeiras linhas dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:50.887551Z",
     "iopub.status.busy": "2023-07-31T22:27:50.886808Z",
     "iopub.status.idle": "2023-07-31T22:27:50.925189Z",
     "shell.execute_reply": "2023-07-31T22:27:50.924246Z",
     "shell.execute_reply.started": "2023-07-31T22:27:50.887485Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Obtenha as informações **tipo** e quantidade de valores **não-nulos** por coluna com *.info()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:50.928351Z",
     "iopub.status.busy": "2023-07-31T22:27:50.927421Z",
     "iopub.status.idle": "2023-07-31T22:27:50.973387Z",
     "shell.execute_reply": "2023-07-31T22:27:50.972544Z",
     "shell.execute_reply.started": "2023-07-31T22:27:50.928304Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Filtre apenas as linhas que possuem \"Churn Reason\" como NaNs usando a função *isna()* e verifique os valores da coluna \"Churn Value\" para elas usando *value_counts()*. \n",
    "\n",
    "**Dica**: Lembre-se que você pode filtrar simplesmente colocando o \"filtro\" ou condição entre chaves.\n",
    "\n",
    "Exemplo: Filtrar todos os valores da coluna CLTV iguais a 0\n",
    "\n",
    "> ```data[data[\"CLTV\"]==0]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:50.974604Z",
     "iopub.status.busy": "2023-07-31T22:27:50.974356Z",
     "iopub.status.idle": "2023-07-31T22:27:50.986127Z",
     "shell.execute_reply": "2023-07-31T22:27:50.985071Z",
     "shell.execute_reply.started": "2023-07-31T22:27:50.974583Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que você infere do resultado acima?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Preencha os NaNs da coluna \"Churn Reason\" com uma string \"NA\" usando a funcão [*fillna()*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:50.987672Z",
     "iopub.status.busy": "2023-07-31T22:27:50.987408Z",
     "iopub.status.idle": "2023-07-31T22:27:50.995898Z",
     "shell.execute_reply": "2023-07-31T22:27:50.994503Z",
     "shell.execute_reply.started": "2023-07-31T22:27:50.987651Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T11:13:40.781775Z",
     "iopub.status.busy": "2023-07-18T11:13:40.781449Z",
     "iopub.status.idle": "2023-07-18T11:13:40.789340Z",
     "shell.execute_reply": "2023-07-18T11:13:40.787797Z",
     "shell.execute_reply.started": "2023-07-18T11:13:40.781744Z"
    }
   },
   "source": [
    "#### **Tarefa**: Vamos remover a coluna com o Churn Score e CLTV usando [*.drop(columns=[])*](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html).\n",
    "O score de churn da IBM e o CLTV foram adquiridos com um sistema interno que desconhecemos e pode até incluir uma rede pré-treinada com um dataset mais amplo que estes, por isso, não adianta usá-lo como *baseline*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T23:46:30.120913Z",
     "iopub.status.busy": "2023-07-31T23:46:30.120576Z",
     "iopub.status.idle": "2023-07-31T23:46:32.088190Z",
     "shell.execute_reply": "2023-07-31T23:46:32.086487Z",
     "shell.execute_reply.started": "2023-07-31T23:46:30.120888Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Olhando para as informações que você obteve com *.info()*, todas as variáveis estão correspondento ao seu melhor *tipo*? Muitas figuram como *object*. Há alguma que precisa ser modificada?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T13:56:02.872240Z",
     "start_time": "2023-07-28T13:56:02.867536Z"
    }
   },
   "source": [
    "**Resposta:**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Converta todas as variáveis não-numéricas (incluindo *Lat Long*) para string para fins de análise usando *.astype('string')*. Faça quaisquer outras modificações devidas para as variáveis numéricas.\n",
    "\n",
    "**Dica**: Se houver alguma variável numérica, você pode usar o [*pd.to_numeric*](https://pandas.pydata.org/docs/reference/api/pandas.to_numeric.html). Fique atento aos possíveis \"erros\" e configure o atributo de erros da função como *errors=\"coerce\"*, que permite a criação de NaNs quando há informação faltante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.009801Z",
     "iopub.status.busy": "2023-07-31T22:27:51.009115Z",
     "iopub.status.idle": "2023-07-31T22:27:51.023780Z",
     "shell.execute_reply": "2023-07-31T22:27:51.022709Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.009768Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa:** Conte novamente quantos nulos há nos dados após as transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.078916Z",
     "iopub.status.busy": "2023-07-31T22:27:51.077917Z",
     "iopub.status.idle": "2023-07-31T22:27:51.096441Z",
     "shell.execute_reply": "2023-07-31T22:27:51.095164Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.078891Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa:** Analise a nova variável com nulos, selecionando apenas as linhas cujos valores para cada uma delas são nulos (separadamente) e avaliando os resultados. Escolha a melhor estratégia para lidar com os nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.098313Z",
     "iopub.status.busy": "2023-07-31T22:27:51.097934Z",
     "iopub.status.idle": "2023-07-31T22:27:51.117070Z",
     "shell.execute_reply": "2023-07-31T22:27:51.115725Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.098282Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Considerando que houvessem NaNs na variável Total Charges e que o Tenure Months (tempo na empresa) fosse não-nulo e maior que zero. Que estratégia você poderia adotar para imputar os valores de Total Charges (TC)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Construa dois histogramas com as variáveis seguintes [sobrepostas no mesmo gráfico](https://www.geeksforgeeks.org/overlapping-histograms-with-matplotlib-in-python/):\n",
    "- $\\text{Total Charges}$\n",
    "- $\\text{Monthly Charges x Tenure Months} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.119212Z",
     "iopub.status.busy": "2023-07-31T22:27:51.118858Z",
     "iopub.status.idle": "2023-07-31T22:27:51.413951Z",
     "shell.execute_reply": "2023-07-31T22:27:51.412419Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.119187Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que podemos dizer quanto à semelhança da distribuição dessas duas variáveis? Apenas com a análise dos histogramas, podemos assumir que elas são equivalentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de Kolmogorov-Smirnov\n",
    "\n",
    "O teste de Kolmogorov-Smirnov (KS) é uma técnica estatística utilizada para verificar a similaridade entre duas distribuições de dados ou para testar se uma amostra de dados segue uma determinada distribuição teórica. Ele é frequentemente usado para comparar uma distribuição de dados observados com uma distribuição teórica, como a distribuição normal. \n",
    "\n",
    "O teste KS calcula a diferença máxima entre as funções de distribuição acumulada (CDF) da amostra observada e da distribuição teórica. Se essa diferença, também chamada de estatística de teste, for menor que um valor crítico específico, podemos aceitar a hipótese nula de que a amostra segue a distribuição teórica.\n",
    "\n",
    "\n",
    "![KS](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/KS_Example.png/300px-KS_Example.png)\n",
    "\n",
    "Principais passos do teste:\n",
    "\n",
    "1) Formulação das hipóteses:\n",
    "\n",
    " - Hipótese nula (H0): As duas amostras são extraídas da mesma distribuição.\n",
    " $$dist(\\text{TC}) = dist(\\hat{\\text{TC}})$$\n",
    " - Hipótese alternativa (H1): As duas amostras não são extraídas da mesma distribuição. \n",
    " $$dist(\\text{TC}) \\neq dist(\\hat{\\text{TC}})$$\n",
    "\n",
    "2) Cálculo da estatística de teste:\n",
    "\n",
    "  - As amostras são combinadas e ordenadas em ordem crescente.\n",
    "  - Para cada valor ordenado, calcula-se a diferença entre as duas CDFs (linha azul e vermelha do gráfico).\n",
    "  - A estatística de teste é a maior diferença absoluta encontrada (seta preta).\n",
    "\n",
    "3) Determinação do valor crítico ou **p-valor**:\n",
    "\n",
    "  - O valor crítico da estatística de teste depende do tamanho das amostras e do nível de significância desejado.\n",
    "  - É possível consultar tabelas ou usar fórmulas específicas para encontrar o valor crítico.\n",
    "\n",
    "4) Comparação e interpretação:\n",
    "\n",
    "  - Se a estatística de teste for menor que o valor crítico, não há evidência suficiente para rejeitar a hipótese nula.\n",
    "  - Se a estatística de teste for maior que o valor crítico, rejeita-se a hipótese nula em favor da hipótese alternativa, concluindo que as duas amostras têm distribuições diferentes.\n",
    "\n",
    "Importante observar que o teste de Kolmogorov-Smirnov é aplicado para amostras de tamanho moderado a grande. Para amostras pequenas, existem correções específicas para garantir que o teste seja adequado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**:  Realize o teste de Kolmogorov-Smirnov para verificar a verossimilhança da hipótese levantada de que as duas distribuições são iguais. Caso sejam, substitua \"Total Charges\" pela multiplicação dada acima. Use a função [ks_2samp](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html) da biblioteca scipy stats para calcular o teste KS.\n",
    "\n",
    "Você pode imputar na função diretamente os valores de cada coluna a ser estudada usando o *.values*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.416199Z",
     "iopub.status.busy": "2023-07-31T22:27:51.415851Z",
     "iopub.status.idle": "2023-07-31T22:27:51.427654Z",
     "shell.execute_reply": "2023-07-31T22:27:51.426308Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.416169Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: A partir da estatística e p-valor calculados pelo teste, podemos rejeitar a hipótese nula de que as distribuições são iguais?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-18T11:38:50.222158Z",
     "iopub.status.busy": "2023-07-18T11:38:50.221639Z",
     "iopub.status.idle": "2023-07-18T11:38:50.229588Z",
     "shell.execute_reply": "2023-07-18T11:38:50.228153Z",
     "shell.execute_reply.started": "2023-07-18T11:38:50.222121Z"
    }
   },
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Substitua total charges pela equação encontrada acima se o teste afirmar que as distribuições são iguais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.429504Z",
     "iopub.status.busy": "2023-07-31T22:27:51.429121Z",
     "iopub.status.idle": "2023-07-31T22:27:51.440181Z",
     "shell.execute_reply": "2023-07-31T22:27:51.439167Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.429478Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análise do target\n",
    "\n",
    "O problema de detecção de churn é um clássico problema de classificação. Ele pode ser visto como um problema de classificação binária ou multiclasses. Geralmente utilizamos a classificação binária (2 classes) para churn. O principal ponto para a decisão entre tratar o problema como classificação binária (classe não churn e classe churn) ou multiclasse (ex: classe não-churn, classe churn tipo 1, classe churn tipo n) tem haver com a **quantidade de amostras** e o **balanceamento** entre as classes.\n",
    "\n",
    "Para conseguir definir se no problema proposto o ideal é usar o cenário multiclasses ou o cenário binário, o ideal seria analisar, para cada proposta de target (binária ou multiclasse) como **cada uma das features está interagindo**. Neste projeto, para fins de simplificação, utilizaremos o caso **binário**. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Calcule as frequências absoluta e relativa para a variável Churn Label.\n",
    "\n",
    "As definições das duas frequências podem ser fácilmente encontras [aqui](https://pt.wikipedia.org/wiki/Frequ%C3%AAncia_(estat%C3%ADstica))\n",
    "\n",
    "**Dica**: Utilize a função para dataframe [.value_counts()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html) para ambos os cálculos. No caso da frequência absoluta, sem nenhum tipo de parâmetro adicional, e para a frequência relativa, utilizando o parâmetro fixado normalize=True, que normaliza a contagem pela valor total.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.441777Z",
     "iopub.status.busy": "2023-07-31T22:27:51.441476Z",
     "iopub.status.idle": "2023-07-31T22:27:51.456411Z",
     "shell.execute_reply": "2023-07-31T22:27:51.454826Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.441748Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie uma visualização com barras por categoria (histograma) para cada variável do target \"Churn Label\" que mostrem as frequências absoluta e relativa calculadas.\n",
    "\n",
    "**Dica**: A função subplots do matplotlib permite que sejam criados multiplos plots na mesma figura. Esses plots podem ser feitos em vários subfiguras (subplots) ou embutidos em uma mesma figura, porém, com eixos verticais distintos (chamados de gêmeos ou *twins*)\n",
    "\n",
    "[Exemplo usando a função subplots e twins](https://stackoverflow.com/questions/65400669/how-to-generate-two-separate-y-axes-for-a-histogram-on-the-same-figure-in-seabor)\n",
    "\n",
    "**OBS**: Esse tipo de visualização será bastante utilizado neste case. Procure uma forma do código ser fácil de adaptar sem muito retrabalho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:51.458508Z",
     "iopub.status.busy": "2023-07-31T22:27:51.458166Z",
     "iopub.status.idle": "2023-07-31T22:27:51.768034Z",
     "shell.execute_reply": "2023-07-31T22:27:51.767165Z",
     "shell.execute_reply.started": "2023-07-31T22:27:51.458480Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** A partir do gráfico, você diria que as classes estão balanceadas? Essa taxa é preocupante do ponto de vista da empresa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo de relacionamento: vamos analisar como o Tenure Month está relacionado com o target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie as visualizações dos histogramas da variável Tenure Months para ambas as classes da variável target Churn Label.\n",
    "\n",
    "**Dica 1**: É possivel visualisar os 2 histogramas na mesma figura de forma sobreposta. Garanta que o histograma que contem menos pontos seja visualisado posteriormente ao com mais pontos (i.e. primeiro o plot do histograma com mais pontos, em seguida o outro),\n",
    "\n",
    "**Dica 2**: Para ajudar o entendimento, utilizando subplots, visualize o boxplot de cada uma das distribuições utilizando a função da biblioteca seaborn [.boxplot()](https://seaborn.pydata.org/generated/seaborn.boxplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:52.716826Z",
     "iopub.status.busy": "2023-07-31T22:27:52.716500Z",
     "iopub.status.idle": "2023-07-31T22:27:53.265337Z",
     "shell.execute_reply": "2023-07-31T22:27:53.263913Z",
     "shell.execute_reply.started": "2023-07-31T22:27:52.716801Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Existe algum indicativo de como o tempo de relacionamento do cliente com a empresa afeta o probabilidade de churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize o teste de Kolmogorov comparando as duas distribuições do tempo de relacionamento condicionalmente às classes de churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:53.266708Z",
     "iopub.status.busy": "2023-07-31T22:27:53.266460Z",
     "iopub.status.idle": "2023-07-31T22:27:53.346437Z",
     "shell.execute_reply": "2023-07-31T22:27:53.345219Z",
     "shell.execute_reply.started": "2023-07-31T22:27:53.266686Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** O que podemos afirmar a partir do teste e das visualizações?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de contrato: Vamos analisar como \"Contract\" se comporta com relação ao target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie plots com barras (histograma) por tipo de contrato por categoria da coluna Churn Label representando as frequências absolutas e relativas de cada uma das combinações.\n",
    "\n",
    "**Dica 1**: Use o mesmo template base feito anteriormente. É preferível e mais fácil que os plots das frequências absoluta e relativa sejam feitas em figuras separadas.\n",
    "\n",
    "**Dica 2**: Utilize a função \n",
    "[.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) do pandas para agrupar a variável churn label e poder calcular as frequências a partir das classes da variável Contract. Isso é o equivalente a calcular a probabilidade $P(\\text{Contract}|\\text{Churn Label} = \\text{Yes})$ e $P(\\text{Contract}|\\text{Churn Label} = \\text{No})$, ou seja, a probabilidade condicional do tipo de contrado sabendo o valor da variável churn.\n",
    "\n",
    "**Dica 3**: Utilize a função [.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) do pandas para ajustar a tabela para que o eixo x da visualização corresponda às classes da variável Churn Label e as barras sejam o tipo de contrato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:54.485481Z",
     "iopub.status.busy": "2023-07-31T22:27:54.485086Z",
     "iopub.status.idle": "2023-07-31T22:27:54.964617Z",
     "shell.execute_reply": "2023-07-31T22:27:54.963705Z",
     "shell.execute_reply.started": "2023-07-31T22:27:54.485454Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Existe algum tipo de contrato que seja mais propenso a ocorrer churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cobrança mensal e total\n",
    "\n",
    "Como vimos anteriormente, temos boas garantias para dizer que: $$\\text{Total Charges} = \\text{Monthly Charges} \\cdot \\text{Total Tenure}$$ \n",
    "\n",
    "Ja vimos a relação que temos de churn com Total Tenure.\n",
    "\n",
    "#### **Pergunta:** Faz sentido investigar as duas variáveis Total Charges e Monthly Charges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie as visualizações dos histogramas da variável Monthly Charges para ambas as classes da variável target Churn Label.\n",
    "\n",
    "**Dica**: Use o mesmo padrão feito para a variável Tenure Months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:55.682963Z",
     "iopub.status.busy": "2023-07-31T22:27:55.682629Z",
     "iopub.status.idle": "2023-07-31T22:27:56.150561Z",
     "shell.execute_reply": "2023-07-31T22:27:56.149599Z",
     "shell.execute_reply.started": "2023-07-31T22:27:55.682937Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize o teste de Kolmogorov comparando as duas distribuições da cobrança mensal condicionalmente às classes de churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:56.152080Z",
     "iopub.status.busy": "2023-07-31T22:27:56.151753Z",
     "iopub.status.idle": "2023-07-31T22:27:56.229454Z",
     "shell.execute_reply": "2023-07-31T22:27:56.228269Z",
     "shell.execute_reply.started": "2023-07-31T22:27:56.152048Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Analisando as figuras e o teste de Kolmogorov, o que podemos concluir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geolocalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procuraremos entender como conjunto de clientes está disperso geograficamente. E como essas variáveis se relacionam com a classe churn. \n",
    "\n",
    "Essas são as colunas que dão indicativo de geolocalização:\n",
    "\n",
    "**'Country', 'State', 'City', 'Zip Code', 'Lat Long', 'Latitude', 'Longitude'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-25T11:24:39.021124Z",
     "iopub.status.busy": "2023-07-25T11:24:39.020630Z",
     "iopub.status.idle": "2023-07-25T11:24:39.030719Z",
     "shell.execute_reply": "2023-07-25T11:24:39.028688Z",
     "shell.execute_reply.started": "2023-07-25T11:24:39.021091Z"
    }
   },
   "source": [
    "#### **Tarefa**: Calcule a frequência absoluta dos clientes para as variáveis Pais, Estado e Cidade.\n",
    "\n",
    "**Dica**: Utilize a função *.groupby()* do pandas para agrupar os valores das tres variáveis e calcule as frequências absolutas utilizando a função *.count()* sobre a variável CustomerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:58.037675Z",
     "iopub.status.busy": "2023-07-31T22:27:58.037370Z",
     "iopub.status.idle": "2023-07-31T22:27:58.061859Z",
     "shell.execute_reply": "2023-07-31T22:27:58.060860Z",
     "shell.execute_reply.started": "2023-07-31T22:27:58.037650Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Quantos paises, estados e cidades estão presentes na base?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie uma visualização no mapa da contagem de clientes por cidade.\n",
    "\n",
    "**Dica**: Utilize a função [scatter_mapbox](https://plotly.com/python/scattermapbox/) da blioteca de visualização plotly express, que permite a criação dos mapas utilizando as variáveis do conjunto de dados Latitude e Logitude. Você pode utilizar diretamente o resultado das frequências absolutas na variável hover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:27:58.063815Z",
     "iopub.status.busy": "2023-07-31T22:27:58.063442Z",
     "iopub.status.idle": "2023-07-31T22:28:00.424133Z",
     "shell.execute_reply": "2023-07-31T22:28:00.422891Z",
     "shell.execute_reply.started": "2023-07-31T22:27:58.063784Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Existe alguma cidade ou região com maior concentração de clientes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie um plot com barras (histograma) para cada uma das top 10 cidades com mais clientes mostrando as frequências absolutas e relativas ordenadas.\n",
    "\n",
    "**Dica**: Use a mesma metodologia aplicada na análise das classes de churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:00.428216Z",
     "iopub.status.busy": "2023-07-31T22:28:00.427281Z",
     "iopub.status.idle": "2023-07-31T22:28:00.811110Z",
     "shell.execute_reply": "2023-07-31T22:28:00.810366Z",
     "shell.execute_reply.started": "2023-07-31T22:28:00.428185Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Com essas visualizações, a distribuição de clientes está coerente com as populações gerais?\n",
    "[Senso americano](https://en.wikipedia.org/wiki/List_of_largest_cities_in_California_by_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie uma visualização de dispersão para mostrar como a probabilidade de churn está relacionada a frequência absoluta de clientes para cada cidade.\n",
    "\n",
    "**Dica 1**: Utilize a função *groupby* do pandas para agrupar cidades e aplique à coluna 'Churn Value' a função [.agg](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.core.groupby.DataFrameGroupBy.agg.html) para calcular tanto a frequência absoluta (usando *count*) quanto a probabilidade de churn (usando *mean*).\n",
    "\n",
    "**Dica 2**: Utilize a função [.scatter](https://matplotlib.org/stable/gallery/shapes_and_collections/scatter.html#sphx-glr-gallery-shapes-and-collections-scatter-py) do matplotlib para criar a visualização de dispersão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:00.813326Z",
     "iopub.status.busy": "2023-07-31T22:28:00.812631Z",
     "iopub.status.idle": "2023-07-31T22:28:01.056242Z",
     "shell.execute_reply": "2023-07-31T22:28:01.055342Z",
     "shell.execute_reply.started": "2023-07-31T22:28:00.813293Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Como está a distribuição de churn segundo essas cidades?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie uma visualização geográfica que mostre a probabilidade de churn para cada cidade.\n",
    "\n",
    "**Dica 1:** Utilize apenas 1 variável Latitude e Longitude para cada cidade. Você pode escolher utilizando a função do pandas [.drop_duplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html) com a escolha do parâmetro subset sendo a variável Cidade.\n",
    "\n",
    "**Dica 2** Crie um dataframe que seja a junção desse dataframe filtrado de Latitude e Longitude por cidade com o dataframe que você calculou as probabilidades de churn por cidade no exemplo acima. Utilize a função [.merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html) para tal junção.\n",
    "\n",
    "**Dica 3** Crie o plot da mesma forma que anteriormente com a função scatter_mapbox, porém com a variável hover sendo essa probabilidade calculada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:01.059547Z",
     "iopub.status.busy": "2023-07-31T22:28:01.057409Z",
     "iopub.status.idle": "2023-07-31T22:28:01.154359Z",
     "shell.execute_reply": "2023-07-31T22:28:01.153496Z",
     "shell.execute_reply.started": "2023-07-31T22:28:01.059501Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta** Conseguimos identificar algum padrão para a probabilidade de churn que indique fator geográfico relevante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipos de serviço\n",
    "\n",
    "Iremos analisar como os tipos de serviço impactam o churn dos consumidores.\n",
    "\n",
    "Na base de dados temos as seguintes colunas:\n",
    "\n",
    "**'Phone Service','Multiple Lines','Internet Service','Online Security','Online Backup','Device Protection','Tech Support','Streaming TV', 'Streaming Movies'**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Podemos usar a correlação de pearson para calcular a relação entre essas variáveis e a variável target?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medindo relacionamento entre variáveis categóricas não-ordinais.\n",
    "\n",
    "Existem algumas formas para medir a relação entre variáveis categóricas não-ordinais, ou que não tenham nenhuma relação de ordem entre sí. Duas maneiras usuais de utilizar algumas medidas estatísticas específicas para esse tipo de dados são: o coeficiente de contingência e o teste qui-quadrado (chi-quadrado).\n",
    "\n",
    " - [**Teste qui-quadrado (chi-quadrado)**](https://pt.wikipedia.org/wiki/Teste_qui-quadrado_de_Pearson): O teste qui-quadrado é um teste estatístico que avalia a associação entre duas variáveis categóricas, comparando as frequências observadas com as frequências esperadas, assumindo que não há associação. Se o valor-p (p-value) do teste qui-quadrado for menor que um nível de significância pré-definido (geralmente 0,05), então rejeita-se a hipótese nula de não associação, o que indica que há uma correlação significativa entre as variáveis.\n",
    "\n",
    "\n",
    " - [**Coeficiente de Contingência:**](https://pt.wikipedia.org/wiki/Coeficiente_de_conting%C3%AAncia) O coeficiente de contingência (ou Cramér's V) é uma medida que varia entre 0 e 1, onde 0 significa nenhuma associação entre as variáveis categóricas e 1 indica uma associação perfeita. Quanto mais próximo de 1, maior é a correlação entre as variáveis.\n",
    "\n",
    "Neste projeto, utilizaremos o **teste qui-quadrado**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Primeiro, copie seu dataframe original, mantendo apenas as colunas dos tipos de serviço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**:  Construa a [tabela de contingência](https://pt.wikipedia.org/wiki/Tabela_de_conting%C3%AAncia) entre o Churn Label e uma variável dos tipos de serviço (por exemplo, \"Phone Service\"). Utlize a função do pandas [pd.crosstab](https://www.statology.org/contingency-table-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Calcule o teste de Qui-quadrado utilizando a função [chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) da biblioteca scipy.stats, passando como parâmetro a tabela de contingência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:01.155900Z",
     "iopub.status.busy": "2023-07-31T22:28:01.155662Z",
     "iopub.status.idle": "2023-07-31T22:28:01.259896Z",
     "shell.execute_reply": "2023-07-31T22:28:01.258498Z",
     "shell.execute_reply.started": "2023-07-31T22:28:01.155878Z"
    }
   },
   "source": [
    "#### **Tarefa**: Repita esse processo para todas as colunas. Você pode incluir o processo em um loop for se preferir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Quais são os 3 tipos de serviço mais relacionados com a variável target? Existe algum que não tenha relação nenhuma?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T13:08:39.023121Z",
     "iopub.status.busy": "2023-07-20T13:08:39.022680Z",
     "iopub.status.idle": "2023-07-20T13:08:39.047240Z",
     "shell.execute_reply": "2023-07-20T13:08:39.046130Z",
     "shell.execute_reply.started": "2023-07-20T13:08:39.023071Z"
    }
   },
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T13:02:28.122371Z",
     "iopub.status.busy": "2023-07-20T13:02:28.121864Z",
     "iopub.status.idle": "2023-07-20T13:02:28.130940Z",
     "shell.execute_reply": "2023-07-20T13:02:28.129523Z",
     "shell.execute_reply.started": "2023-07-20T13:02:28.122333Z"
    }
   },
   "source": [
    "### Servicos de Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie um plot com barras (histograma) por categoria da variável *Internet Service* mostrando as frequências absolutas e relativas ordenadas.\n",
    "\n",
    "**Dica**: Utilize a mesma metodologia aplicada às classes de chunr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:01.261930Z",
     "iopub.status.busy": "2023-07-31T22:28:01.261591Z",
     "iopub.status.idle": "2023-07-31T22:28:01.646603Z",
     "shell.execute_reply": "2023-07-31T22:28:01.645094Z",
     "shell.execute_reply.started": "2023-07-31T22:28:01.261893Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie plots com barras (histograma) por categoria da variável *Internet Service* e por categoria da coluna Churn Label representando as frequências absolutas e relativas de cada uma das combinações.\n",
    "\n",
    "**Dica 1**: Use o mesmo template base feito anteriormente para a variável tipo de contrato.\n",
    "\n",
    "**Dica 2**: Utilize a função \n",
    "[.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) do pandas para agrupar a variável churn label e poder calcular as frequências a partir das classes da variável Internet Service. Isso é o equivalente a calcular a probabilidade $P(\\text{Internet Service}|\\text{Churn Label} = \\text{Yes})$ e $P(\\text{Internet Service}|\\text{Churn Label} = \\text{No})$, ou seja, a probabilidade condicional do tipo de serviço de internet sabendo o valor da variável churn.\n",
    "\n",
    "**Dica 3**: Utilize a função [.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) do pandas para ajustar a tabela para que o eixo x da visualização corresponda às classes da variável Churn Label e as barras sejam os tipos de serviço de internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:01.647950Z",
     "iopub.status.busy": "2023-07-31T22:28:01.647683Z",
     "iopub.status.idle": "2023-07-31T22:28:02.206959Z",
     "shell.execute_reply": "2023-07-31T22:28:02.205578Z",
     "shell.execute_reply.started": "2023-07-31T22:28:01.647928Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie plots com barras (histograma) por categoria da variável *Internet Service* e por categoria da coluna Churn Label representando as frequências absolutas e relativas de cada uma das combinações, porém, considerando o eixo X como sendo os tipos de Internet Service.\n",
    "\n",
    "**Dica 1**: Use o mesmo template base feito acima.\n",
    "\n",
    "**Dica 2**: Utilize a função \n",
    "[.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) do pandas para agrupar a variável Internet Service e poder calcular as frequências a partir das classes da variável Churn Label. Isso é o equivalente a calcular a probabilidade $P(\\text{Churn Label} | \\text{Internet Service} = \\text{DSL})$, $P(\\text{Churn Label} | \\text{Internet Service} = \\text{Fiber optic})$, ou seja, a probabilidade condicional do churn sabendo o valor da variável Internet Service..\n",
    "\n",
    "**Dica 3**: Utilize a função [.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) do pandas para ajustar a tabela para que o eixo x da visualização corresponda às classes da variável Internet Services e as barras sejam as classes da variável Churn Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:02.208735Z",
     "iopub.status.busy": "2023-07-31T22:28:02.208380Z",
     "iopub.status.idle": "2023-07-31T22:28:02.708001Z",
     "shell.execute_reply": "2023-07-31T22:28:02.705802Z",
     "shell.execute_reply.started": "2023-07-31T22:28:02.208704Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Existe alguma predileção por serviços de internet para clientes que tem mais propensão ao churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T13:36:54.540553Z",
     "iopub.status.busy": "2023-07-20T13:36:54.540189Z",
     "iopub.status.idle": "2023-07-20T13:36:54.561605Z",
     "shell.execute_reply": "2023-07-20T13:36:54.560286Z",
     "shell.execute_reply.started": "2023-07-20T13:36:54.540525Z"
    }
   },
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize as mesmas análises feitas para a variável *Internet Service*, agora considerando a variável *Tech Support* e a target *Churn Label*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:04.357428Z",
     "iopub.status.busy": "2023-07-31T22:28:04.357047Z",
     "iopub.status.idle": "2023-07-31T22:28:04.391096Z",
     "shell.execute_reply": "2023-07-31T22:28:04.390186Z",
     "shell.execute_reply.started": "2023-07-31T22:28:04.357397Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que podemos observar da relação entre as variáveis *Tech Support* e da variável target *Churn Label*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-20T16:53:48.301504Z",
     "iopub.status.busy": "2023-07-20T16:53:48.301091Z",
     "iopub.status.idle": "2023-07-20T16:53:48.329200Z",
     "shell.execute_reply": "2023-07-20T16:53:48.327286Z",
     "shell.execute_reply.started": "2023-07-20T16:53:48.301470Z"
    }
   },
   "source": [
    "#### **Tarefa**: Crie plots com barras (histograma) por categoria da variáveis *Internet Service*,*Tech Support* e por categoria da coluna Churn Label representando as frequências absolutas e relativas de cada uma das combinações, porém, considerando o eixo X como sendo a combinação entre os tipos de *Internet Service* e *Tech Support*.\n",
    "\n",
    "**Dica 1**: Use o mesmo template base feito para as variáveis acima.\n",
    "\n",
    "**Dica 2**: Utilize a função \n",
    "[.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) do pandas para agrupar as variáveis ['Internet Service','Tech Support'] e poder calcular as frequências a partir das classes da variável Churn Label. Isso é o equivalente a calcular a probabilidade $P(\\text{Churn Label} | \\text{Internet Service} = \\text{DSL}, \\text{Tech Support} = \\text{Yes})$, por exemplo, ou seja, a probabilidade condicional do churn sabendo o valor da variável Internet Service e da variável Tech Support.\n",
    "\n",
    "**Dica 3**: Utilize a função [.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) do pandas para ajustar a tabela para que o eixo x da visualização corresponda às classes das variáveis ['Internet Service','Tech Support'] e as barras sejam as classes da variável Churn Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:04.392719Z",
     "iopub.status.busy": "2023-07-31T22:28:04.392435Z",
     "iopub.status.idle": "2023-07-31T22:28:04.925325Z",
     "shell.execute_reply": "2023-07-31T22:28:04.923906Z",
     "shell.execute_reply.started": "2023-07-31T22:28:04.392693Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Como o relacionamento entre as 2 variáveis *Internet Service* e *Tech Support* interferem na probabilidade de churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segurança Online"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize as mesmas análises feitas para a variável *Internet Service*, agora considerando a variável *Online Security* e a taget *Churn Label*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:06.675799Z",
     "iopub.status.busy": "2023-07-31T22:28:06.675512Z",
     "iopub.status.idle": "2023-07-31T22:28:06.707422Z",
     "shell.execute_reply": "2023-07-31T22:28:06.706234Z",
     "shell.execute_reply.started": "2023-07-31T22:28:06.675773Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que podemos entender da relação entre *Online Security* e *Churn Label*? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de pagamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize as mesmas análises feitas para a variável *Internet Service*, agora considerando a variável *Payment Method* e a taget *Churn Label*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:06.708880Z",
     "iopub.status.busy": "2023-07-31T22:28:06.708611Z",
     "iopub.status.idle": "2023-07-31T22:28:07.105021Z",
     "shell.execute_reply": "2023-07-31T22:28:07.104055Z",
     "shell.execute_reply.started": "2023-07-31T22:28:06.708857Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Como se dá a relação entre as variáveis *Payment Method* e *Churn Label*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T11:26:56.260941Z",
     "iopub.status.busy": "2023-07-21T11:26:56.260062Z",
     "iopub.status.idle": "2023-07-21T11:26:56.287130Z",
     "shell.execute_reply": "2023-07-21T11:26:56.285478Z",
     "shell.execute_reply.started": "2023-07-21T11:26:56.260890Z"
    }
   },
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie plots com barras (histograma) por categoria da variáveis *Internet Service*,*Payment Method* e por categoria da coluna Churn Label representando as frequências absolutas e relativas de cada uma das combinações, porém, considerando o eixo X como sendo a combinação entre os tipos de *Internet Service* e *Payment Method*.\n",
    "\n",
    "**Dica 1**: Use o mesmo template base feito na análise de Tech Support e Internet Services.\n",
    "\n",
    "**Dica 2**: Utilize a função \n",
    "[.groupby](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) do pandas para agrupar as variáveis ['Internet Service','Payment Method'] e poder calcular as frequências a partir das classes da variável Churn Label. Isso é o equivalente a calcular a probabilidade $P(\\text{Churn Label} | \\text{Internet Service} = \\text{DSL}, \\text{Payment Method} = \\text{Electronic check})$, por exemplo, ou seja, a probabilidade condicional do churn sabendo o valor da variável Internet Service e da variável Payment Method.\n",
    "\n",
    "**Dica 3**: Utilize a função [.pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) do pandas para ajustar a tabela para que o eixo x da visualização corresponda às classes das variáveis ['Internet Service','Payment Method] e as barras sejam as classes da variável Churn Label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:08.250792Z",
     "iopub.status.busy": "2023-07-31T22:28:08.250493Z",
     "iopub.status.idle": "2023-07-31T22:28:08.923544Z",
     "shell.execute_reply": "2023-07-31T22:28:08.922540Z",
     "shell.execute_reply.started": "2023-07-31T22:28:08.250766Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta** Como está a relação entre as três variáveis? O que podemos inferir exclusivamente da combinação Fibra-Otica e Electronic check?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis de Cliente\n",
    "\n",
    "Iremos analisar como os as variáveis de cliente impactam o churn dos consumidores.\n",
    "\n",
    "Na base de dados temos as seguintes colunas:\n",
    "\n",
    "**'Gender','Senior Citizen','Partner','Dependents'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Faça as mesmas análises que você fez para os tipos de serviço para cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:08.925270Z",
     "iopub.status.busy": "2023-07-31T22:28:08.924980Z",
     "iopub.status.idle": "2023-07-31T22:28:08.991779Z",
     "shell.execute_reply": "2023-07-31T22:28:08.990781Z",
     "shell.execute_reply.started": "2023-07-31T22:28:08.925246Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação de dados para modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos anteriormente que várias variáveis influenciam na probabilidade de churn. Iremos inciar aqui nessa sessão a seleção e a preparação de dados para a modelagem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie um dataset que seleciona apenas as colunas que iremos utilizar na modelagem considerando também uma coluna para a variável target.\n",
    "\n",
    "**Dica 1**: Utilize o conhecimento que você adquiriu durante a análise de dados para escolher as colunas que tenham potencial de relação com o target.\n",
    "\n",
    "**Dica 2**: Cuidado com o numero elevado de colunas. Quanto mais colunas, mais são necessárias amostra para o modelo ter uma performance adequada.\n",
    "\n",
    "**Dica 3**: Em um primeiro momento, prefira não envolver dados de geolocalização. A menos que você tenha descoberto alguma relação entre as variáveis ou entre alguma transformação delas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.395971Z",
     "iopub.status.busy": "2023-07-31T22:28:10.395599Z",
     "iopub.status.idle": "2023-07-31T22:28:10.407794Z",
     "shell.execute_reply": "2023-07-31T22:28:10.406348Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.395942Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie dois dataframes separados, um contendo apenas as variáveis categóricas e o outro contendo as demais colunas.\n",
    "\n",
    "**Dica 1**: A função do pandas [select_dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) pode ser útil para definir as colunas não-categóricas.\n",
    "\n",
    "**Dica 2**: Existe uma coluna no dataset que já considera o target como sendo numérico, portando de preferência para escolha dessa coluna como target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.410352Z",
     "iopub.status.busy": "2023-07-31T22:28:10.409967Z",
     "iopub.status.idle": "2023-07-31T22:28:10.421507Z",
     "shell.execute_reply": "2023-07-31T22:28:10.420037Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.410326Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Transforme as variáveis categóricas em numéricas utilizando OneHotEncoding.\n",
    "\n",
    "**Dica 1**: Você pode fazer de maneira manual ou utilizando a função do pandas [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) para essa transformação. Para evitar redundância de resultados, fixe o parâmetro drop_first=True se for usar o pandas. Essa escolha remove 1 coluna do dadaset.\n",
    "\n",
    "**Dica 2**: Você pode converter todas as colunas categoricas de uma única vez com essa função, porém, por conta do drop_first, algumas colunas que podem ser mais fáceis de interpretar pode ser removidas. Investigue se a trasnformação está boa para a sua análise e, caso contrário, realize a operação individualizada para essas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.424214Z",
     "iopub.status.busy": "2023-07-31T22:28:10.423683Z",
     "iopub.status.idle": "2023-07-31T22:28:10.465539Z",
     "shell.execute_reply": "2023-07-31T22:28:10.464641Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.424172Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Concatene todas as colunas transformadas e as que não foram no mesmo dataset.\n",
    "\n",
    "**Dica**: Utilize a função do pandas [pd.concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html) para essa junção. Como faremos a junção de colunas, utilize o parâmetro axis=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.467015Z",
     "iopub.status.busy": "2023-07-31T22:28:10.466687Z",
     "iopub.status.idle": "2023-07-31T22:28:10.473329Z",
     "shell.execute_reply": "2023-07-31T22:28:10.472169Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.466986Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de previsão do churn\n",
    "\n",
    "Neste projeto, vamos lidar com o problema de churn, construindo um modelo de classificação binária. O modelo utilizado será o XGBoost. O XGBoost é um modelo que necessita da estimação de diversos hiperparâmetros e, por isso, vamos implementar uma busca em grade ou *grid-search*.\n",
    "\n",
    "O Grid Search é uma técnica utilizada para encontrar a melhor combinação de hiperparâmetros para um modelo de aprendizado de máquina. Esses hiperparâmetros são valores ajustáveis que não são aprendidos pelo modelo durante o treinamento, mas que podem influenciar significativamente sua performance. O Grid Search realiza uma busca exaustiva em um espaço **pré-definido** de hiperparâmetros, combinando todas as possíveis combinações e avaliando o desempenho do modelo com cada uma delas. Para cada combinação de hiperparâmetros, o Grid Search utiliza uma **estratégia de validação cruzada** para avaliar a performance do modelo de forma mais robusta. Ao final da busca, o Grid Search retorna a combinação de hiperparâmetros que resultou no melhor desempenho, permitindo assim que o modelo seja configurado de maneira ótima para a tarefa em questão.\n",
    "\n",
    "Todos os conceitos necessários para completarmos a tarefa são descritos abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocolos de validação\n",
    "\n",
    "Existem várias técnicas de validação que podem ser utilizadas para avaliar o desempenho de modelos de aprendizado de máquina. Em grandes linhas, podemos destacar as seguintes:\n",
    "\n",
    "\n",
    "- **Amostragem de retenção (*Hold-out*)**:\n",
    "    O hold-out é uma das abordagens mais simples e populares para dividir o conjunto de dados em um conjunto de treinamento e um conjunto de teste. Nesta técnica, você reserva uma parte dos dados (por exemplo, 70-80%) para treinar o modelo e a outra parte (por exemplo, 30-20%) para testá-lo. Apesar de sua simplicidade, essa técnica pode ser propensa a variações nos resultados, dependendo de como os dados são divididos. A escolha aleatória das amostras pode levar a resultados variáveis, o que pode não ser uma estimativa precisa do desempenho geral do modelo. Isso acontece especialmente quando o conjunto de dados é pequeno ou quando há desequilíbrio entre as classes (em problemas de classificação). Porém, para conjuntos de dados com alto volume de amostras, essas variações são mitigadas além de fornecer um processamento mais rápido que em outras técnicas.\n",
    "     \n",
    " ![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAWcAAACMCAMAAACXkphKAAACIlBMVEX///8AAAD6+vpMTExBQUFnZ2e3t7dXV1e6urqbm5vT09Pw7//a5f8TU6r5+P9HDyZSacl/RTT/6PfnUx+zx/+Ajd3/2OoAT5/aclsDdNydTDL/6uXs8//k5OTO2v/c7f8AAHAAL7m5zv/z8/PAwP8bNHLNlog0JFIVFRUAKJLkhIr6nYp/p/5rFiv/xLPEZ0wALXiqrf/kv7X/jGjY1/90dHSHh4cuLi7Hx8dQbcUbJ17TpJinp6cARaReAAALOW/IWT3l2dq8u/8AF2fJjn6doP0YAEFCV7FONjrqsMHNPwBCT2M9RDvnmKG4v+4mL3QABBM3JyIzQkVMVDnvpcE4WYH+saSapOhxgNkrHx//xtuOWoEAIgIAJBlsQRy9xnuMleIALDgAGVO31///mHgJNrWiamL/gVhYOynUmJsgAAAAACGUV1VoIQBqj+00Bj8uOEkwBEoAHDN7DwDTV0srACT7yMkAETl0OUopGy9Vf8xtjJVEFgC9c3RXcrZAQEjJkL29f2mzvtJuc16tfHZ/mM1+gpp5kLQkKDoAVd+lQgD/4NhLT41GM1iuLwDXUjj9xfWKe3C8n52bl4GKsOl8ldMeJkdMFlY1I3W0bIpNT73ynJJahfJgLCgAD5X71PUuePd6gbdZCwx+UDs4AABYaH10IACpX2rUt7aPbHxwZJxwO3ZYQIehiJJYO5lbOlHheYChZMAAAGMAB7PWu8mGP2g6cOI2AAAHBklEQVR4nO2d6V8TRxiAJ5sNGzZxjZGAmk1QAgUKVUQSrgQBOTw4lEYSY7UpYBALqEVBqdrWorGi1gNpRbGVWksPa2vt/9eZTbj6M7AbkkmI7/OFnexM8u6Tybuzs8mAEAAAAAAAAAAAAAAAAAAAAAAAAAAAkWFsGGbxAwwTqa4QeRewPHpXjd2+u7ZuQWD9noZIlRubSqkElYLo121EKLt57775R3Lz3otUeWc+eI4SyTPSZ+1HKOcA29KK2toPHurYFS4gZGj50I3dH2Y7OpGnSnWooyjREa9NQp4F7xGf9SgjmD5yh/ozLjCmY25kOG60fmzMwKmkuKkT+nP0hD37P3GTUndXz0Le6K7q0TVvMOO9phpcPBEwgueo+Z/nql2LPffiXnyyD6fvU2q1+tP+xHvmOEs0zRwq1hbrUBQS8ixWDmQKg6fVZ1Rhz8LgWfWZg714l+GzIV3lUKhyoj1zKpUqCtEO3Cw99tEoIuTZmnVO8J4fXujPptO4kEc8o+IRt3fAKFVuTALPKl5pK6I5OTx3774wjEwXfcwo7s9lhQEB+Sf3odGDvdmf+wTvpcyMrssCGqxGuXv6EhqshRhzKGwkabbHJR4F6K+wLBmzka0vWr680oOzw+HyTt1oqFB8hj3pk8Z1bADXMR1gtycyWksBdpamqImkWROneFKWNJVC0UxS9OY1h0WtUDQLvTk6ypWItklvizOuAaUqCtQxnNI0A8zDaGTKS2NJ0lCp1EA0cFLm4FbUzKuAGLDihQd4jgkremYciQ4xFZAzMZSO65WvXA14G+Tau6BCXl3yhqgTPVO3NpGyrtzrO+nqkYV7x1FgJ+pkz41qpRwTz3hSFCfJGgoygSRa8UzqO480MSozOYcgogtAtELIpSCn6MQmzddFcxPmXcYexUDNUg6ZQylkWkjp7RRyb0ADYztF8FFoxqItoFkhFgsMhgEAAAAAAAAAWOMwwKqRoTmN1u3KVAY80wE800GmZ7UmdSBfZONovmC5fM9aGfXWCuQbKVTvWXDgmQrgmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ7gmQ6J9Kwni+7MMfiVOdbPvwwrer6q0djtGs3XviWP6q6NhbfEaxrNoojLrq+w4BUlz0GWvXGEZZeGrXdtXCh8c3P8rS1zbrEdtQsHtPN2TFbwWtEzYxNN6zMZ29IvA+gM4QXbhMo7ZtF/bn5HfVf18i9IrT8Lhg3GKJpZXd8iNPF4vhyjldJk5A0BeyZ/rFptHQmE/PHcqtGWkje9vqtPkGrprqZpx5HePzKmHV7u2ah51kme9cG7wXtv0DW7474ZicFqZA36Htof4AOaqDYLD0v99geky0/YHQ5HNelLjZPhhXHLgnb7MGq7dZGzd64qEAn5nj3fOYPfdyJ91qPgg8x5z2Vbd0iVskcvaCsvjOufjYylJZNna+HZHhuaum/zT7YK2VmbUMbWgcd6VyATbd5iFredOide2etDE+uLcvP6yVEi69b90kfXmhWwPZkeFvz5s7YYJHLZnsWnfQh5p3/w1jCIQfMLPSLv5BFycmk760M6V0DIrUqWvDHn+Wa4vLnWHPLci1DxwHDI836yMmuROIWr/rhByteCJ0+1CW+ZZgQknAgItPNGY/79iopnx9ye15dx9ljwjHKudw2VCoaZigq+8KfM+qTz/H64vPlO2HMR9vzB9pDnHQzKKdklNi94xk2cJTXVYvNMuiP9db+Rtufi8/ecTmeaUbxa+LxhsWdyhn6eWTmD9zorhOT0LBha2JHInlHxpfEyV2D+tKmvvHR33ZDFQn5XR78/z72erq2pdYln5Glyz5WT0nPZ04CwXH/WNU//zC1ec990w135IrRJ23OZ6xcjEuuQxYwy9rSKc2Fk15Gx3XGfZ7IV94M6lFsSce36EAnxXNKAuvMie9Y3b8EfxlmpWdssg8fZN43SAdWXkgHVqsIII8ez97k03mj/1fnbS/Tw9/T2fiPy7H40S07DOe1j6df/eIxE0+2Xzj9LkTD16mWSjDemyFrB1qd/4W3DyN4Df2PPrlqU8Zp4rsGeX5jFf2oZ6cT4ZPoN730lDehySk5yHUfHkeDvUnP/mvHbla+Owcqscq67dTwZIjN6nsedV+R53oblZ/Oh/3SBH+WJcIGXduPK/LLDoGSc38jpwiNkZtvlOP5k952a34iE1Me7m+K5dDN4RmTx/SpOU9UQzx/tg2cJxmaL7+/8wTMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdwDMdktmzomW5kxxnEnsuZ1OHctrHUyDfM7BKwDMdwDMdZHhOORxcKg2fAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACC5+Q928kN1RMODGwAAAABJRU5ErkJggg==)\n",
    "\n",
    "- **Validação Cruzada (*Cross-Validation*)**:\n",
    "    A validação cruzada é uma técnica mais sofisticada que ajuda a obter estimativas mais estáveis do desempenho do modelo. Existem várias formas de validação cruzada, sendo a validação cruzada k-fold a mais comum. Nessa abordagem, o conjunto de dados é dividido em k partes (dobras) de tamanho igual. O modelo é treinado k vezes, cada vez usando k-1 dobras como conjunto de treinamento e a dobra restante como conjunto de teste. Ao final das k iterações, os resultados de desempenho do modelo (por exemplo, métricas de avaliação) são agregados e geralmente são calculadas médias ou medianas para fornecer uma estimativa mais precisa do desempenho geral do modelo. \n",
    "    A validação cruzada é especialmente útil quando o tamanho do conjunto de dados é limitado ou quando há uma distribuição desigual de classes, pois permite que todas as amostras contribuam tanto para o treinamento quanto para a avaliação do modelo, reduzindo assim o impacto de variações na divisão dos dados. Ao usar técnicas de validação cruzada, é importante ter em mente que a estimativa do desempenho do modelo pode depender da escolha de k. Geralmente, valores comuns para k são 5 ou 10, mas em casos de conjuntos de dados muito pequenos, o LOOCV (Leave-One-Out Cross-Validation) pode ser considerado, onde cada amostra é usada como conjunto de teste uma vez, enquanto todas as outras amostras são usadas para treinar o modelo. O LOOCV fornece uma estimativa não enviesada do desempenho do modelo, mas pode ser computacionalmente mais intensivo.\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"crossval\" width=\"40%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie suas variáveis X e y, onde X são as features do seu modelo e y a target. Depois, separe um conjunto de TESTE usando a amostragem de retenção para que possamos fazer uma \"simulação da realidade\" com dados não-vistos. Você pode usar a função [*train_test_split*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do sklearn e um tamanho de dataset de teste de 20%.\n",
    "\n",
    "**Dica**: Lembre-se que nosso dataset é extremamente desbalanceado, por isso, é importante \"estratificar\", ou seja, garantir que temos a mesma proporção de target tanto no subconjunto de treino, quando de teste. Para isso, você pode parametrizar o atributo de entrada da função train_test_split com *stratify=y*, sendo y sua target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.475003Z",
     "iopub.status.busy": "2023-07-31T22:28:10.474652Z",
     "iopub.status.idle": "2023-07-31T22:28:10.502618Z",
     "shell.execute_reply": "2023-07-31T22:28:10.501364Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.474970Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validação Cruzada Estratificada \n",
    "\n",
    "Para a validação no treino, utilizaremos avalidação cruzada. Dado o tamanho do conjunto de dados, a estratégia Leavo-One-Out parece não ser uma boa escolha pelo tempo de processamento necessário. Poderíamos então utilizar a K-fold cross validation? Talvez não seja a melhor opçãopor termos classes **desbalanceadas**. Numa amostragem aleatória, temos muita chance de ter um resultado ruidoso devido a falta de amostras da classe minoritária nos folds de treinamento. Uma forma de trazer robustez a saída é utilizando a **Validação Cruzada Estratificada**.\n",
    "\n",
    "A Validação Cruzada Estratificada ([StratifiedKFold no sklearn](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold)) é uma técnica de validação cruzada que divide o conjunto de dados em k partes (dobras) de forma estratificada, preservando a proporção de classes em cada subconjunto. É especialmente útil quando se tem classes desequilibradas, garantindo que cada subconjunto tenha uma distribuição similar de classes. Geralmente, o StratifiedKFold é utilizado uma única vez para dividir o conjunto de dados em k subconjuntos e treinar/testar o modelo em cada uma delas.\n",
    "\n",
    "![image.png](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_009.png)\n",
    "\n",
    "Indo além, contamos também com a possibilidade de utilizar a Validação Cruzada Estratificada Repetida ([RepeatedStratifiedKFold do sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold)) que é uma extensão do StratifiedKFold que repete a validação cruzada estratificada múltiplas vezes para melhorar a robustez das estimativas de desempenho do modelo. Além de dividir o conjunto de dados em k partes estratificadas, ele repete esse processo n vezes, gerando diferentes divisões aleatórias dos dados em cada repetição. A repetição é útil quando o conjunto de dados é relativamente pequeno ou quando se deseja obter uma estimativa mais estável e confiável do desempenho do modelo, levando em conta a variabilidade decorrente da aleatoriedade das divisões dos dados.\n",
    "\n",
    "\n",
    "Para o nosso problema utilizaremos a forma não repetida, devido aos tempos de treinamento e o caráter didático. Porém, se quiserem testar a com repetição, fiquem à vontade. E, por favor, comentem sobre os resultados conosco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Defina um objeto com a validação cruzada. Esse objeto será utilizado mais à frente.\n",
    "\n",
    "[StratifiedKfold](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold)\n",
    "\n",
    "**Dica**: Aplique 4 splits e use shuffle=True. Caso queira ter resultados replicáveis, fixe um random_state qualquer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.504058Z",
     "iopub.status.busy": "2023-07-31T22:28:10.503764Z",
     "iopub.status.idle": "2023-07-31T22:28:10.508636Z",
     "shell.execute_reply": "2023-07-31T22:28:10.507731Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.504034Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Como podemos resolver o problema de desbalanceamento das classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Técnicas para tratar o desbalanceamento\n",
    "\n",
    "Uma das principais estratégias para lidar com o desbalanceamento de classes é a reamostragem do conjunto de treinamento. Na reamostragem, podemos aplicar o *undersampling* e o *oversampling*. \n",
    "- *Undersampling* ou subamostragem: remoção estratégica de amostras da classe majoritária para reduzir o viés em direção a essa classe.\n",
    "- *Oversampling*: aumento de amostras da classe minoritária. Uma eficiente técnica de oversampling é o SMOTE (Synthetic Minority Over-sampling Technique), que cria amostras sintéticas da classe minoritária para equilibrar as proporções das classes. Ele utiliza uma abordagem similar à do KNN.\n",
    "\n",
    "![smote](https://www.researchgate.net/publication/347937180/figure/fig3/AS:973429209563136@1609095017080/Illustration-of-the-SMOTE-oversampling-approach.ppm)\n",
    "\n",
    "Outra abordagem eficaz é o uso de **modelos ensemble**, como Random Forest, Gradient Boosting e XGBoost. Esses modelos têm a capacidade de combinar as previsões de vários classificadores, reduzindo o impacto do desequilíbrio e fornecendo uma classificação mais robusta. Os modelos ensemble também podem ser menos sensíveis aos problemas causados pelo desbalanceamento, tornando-os uma opção valiosa.\n",
    "\n",
    "Para lidar com a questão do peso das features, podemos aplicar técnicas de seleção de features. A seleção adequada das características mais relevantes para o problema pode ajudar a melhorar a representatividade do conjunto de dados e, consequentemente, a eficácia do modelo.\n",
    "\n",
    "Outra estratégia importante é ajustar os pesos das classes durante o treinamento do modelo. **Atribuir maior peso à classe minoritária** faz com que o modelo dê mais importância a ela durante o aprendizado, ajudando a corrigir o viés em direção à classe majoritária.\n",
    "\n",
    "\n",
    "No nosso problema, iremos utilizar algumas delas: o **SMOTE**, o modelo **XGBOOST** e adicionar à pesquisa de hiperparâmetros, com GridSearch, **pesos para classe minoritária** (parâmetro scale_pos_weight do XGBOOST).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST\n",
    "\n",
    "O XGBoost (Extreme Gradient Boosting) é um algoritmo de aprendizado de máquina que utiliza a técnica de gradient boosting para construir modelos de alta precisão. Vamos explicar o funcionamento do XGBoost em um passo a passo simples:\n",
    "\n",
    "1. Inicialização dos pesos: O processo começa atribuindo pesos iguais a todas as instâncias de treinamento. Esses pesos são usados para dar mais importância às instâncias que foram classificadas incorretamente nas etapas anteriores.\n",
    "\n",
    "2. Etapas iterativas: O XGBoost cria árvores de decisão em etapas iterativas. Em cada iteração, uma nova árvore é adicionada ao modelo para corrigir os erros cometidos pelas árvores anteriores.\n",
    "\n",
    "3. Cálculo do gradiente e hessiano: Para cada instância de treinamento, o XGBoost calcula o gradiente e o hessiano da função de perda, que medem a direção e a magnitude do erro em relação à previsão atual.\n",
    "\n",
    "4. Construção da árvore: Com base nos gradientes e hessianos calculados, o XGBoost constrói uma árvore de decisão para minimizar a função de perda. Essa árvore é adicionada ao modelo.\n",
    "\n",
    "5. Regularização: O XGBoost utiliza técnicas de regularização, como penalização L1 e L2, para evitar overfitting e melhorar a generalização do modelo.\n",
    "\n",
    "6. Atualização dos pesos: Após a construção da árvore, os pesos das instâncias de treinamento são atualizados com base nos erros cometidos pela nova árvore.\n",
    "\n",
    "7. Atualização do modelo: O processo de construção de árvores e atualização de pesos é repetido várias vezes (número de iterações definido pelo usuário) para criar um modelo final que combina as previsões de todas as árvores.\n",
    "\n",
    "![xgboost](https://miro.medium.com/v2/resize:fit:560/1*85QHtH-49U7ozPpmA5cAaw.png)\n",
    "\n",
    "O XGBoost é conhecido por sua eficiência e precisão em problemas de classificação e regressão. Ele é amplamente utilizado em competições de ciência de dados e é uma das bibliotecas de machine learning mais populares. Sua flexibilidade, recursos de regularização (imploementação interna de normas l1 e l2) e capacidade de lidar com grandes conjuntos de dados (possibilidade de processamento paralelo) tornam-no uma escolha poderosa para muitas tarefas de aprendizado de máquina. É importante destacar que o XGBoost tem uma maneira interna eficiente de tratar dados faltantes e, portanto, você pode colocar NaNs em sua entrada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Complete o estimador abaixo com a função objetiva correta. Lembre-se que temos um problema de classificação binária.\n",
    "\n",
    "**Dica**: Dentre as funções objetivas possíveis para classificações binárias, a mais comumente utilizadas é a *binary:logistic*, que oferece a probabilidade como output.\n",
    "\n",
    "[XGBoost - GetStarted](https://xgboost.readthedocs.io/en/stable/get_started.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.509849Z",
     "iopub.status.busy": "2023-07-31T22:28:10.509606Z",
     "iopub.status.idle": "2023-07-31T22:28:10.673465Z",
     "shell.execute_reply": "2023-07-31T22:28:10.672497Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.509828Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definição do Modelo e dos hiperparâmetros a serem pesquisado\n",
    "estimator = XGBClassifier(\n",
    "    objective= ???, #adicione a função objetiva relativa à classificação binária\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Complete o dicionário de parâmetros abaixo com diferentes valores de parâmetros para serem testados no modelo. Não se esqueça de setar valores maiores que 1 para o hiperparâmetro \"classifier__scale_pos_weight\" para tratar o desbalanceamento das classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.674840Z",
     "iopub.status.busy": "2023-07-31T22:28:10.674589Z",
     "iopub.status.idle": "2023-07-31T22:28:10.679960Z",
     "shell.execute_reply": "2023-07-31T22:28:10.678571Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.674817Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'classifier__max_depth':  [3,10,15], # exemplo de entrada\n",
    "    'classifier__n_estimators': [???], # complete com no máximo 3 valores entre 100 e 1000 em formato de lista\n",
    "    'classifier__learning_rate': [???], # complete com no máximo 3 valores entre 0.01 e 1 em formato de lista\n",
    "    'classifier__scale_pos_weight': [???] # complete com no máximo 3 valores entre 1 e 20 em formato de lista\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines\n",
    "\n",
    "Uma pipeline é uma sequência ordenada de etapas de pré-processamento e modelagem em um fluxo de trabalho de aprendizado de máquina. Ela permite automatizar e organizar a execução de diversas tarefas, como tratamento de dados faltantes, normalização, seleção de características e treinamento de modelos, em uma única estrutura. A utilização de pipelines proporciona benefícios significativos, pois torna o processo mais eficiente, evita vazamento de informações, melhora a reprodutibilidade e facilita a experimentação com diferentes combinações de etapas e hiperparâmetros. Além disso, a pipeline possibilita a implantação de modelos em produção de forma mais confiável, uma vez que as etapas são padronizadas e organizadas, garantindo que novos dados sigam o mesmo tratamento aplicado durante o treinamento.\n",
    "\n",
    "**Aqui, utilizamos a pipeline sobretudo para garantir que todas as etapas serão aplicadas em todos os subconjuntos da validação cruzada.**\n",
    "\n",
    "Uma das pipelines mais populares é a do [Sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Aqui, utilizaremos a pipeline da biblioteca [imbalanced learn](http://glemaitre.github.io/imbalanced-learn/generated/imblearn.pipeline.Pipeline.html), pois ela de adequa ao SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie um pipeline com a biblioteca do [imbalanced learn](http://glemaitre.github.io/imbalanced-learn/generated/imblearn.pipeline.Pipeline.html) que tenha como passos primeiro o SMOTE e, em seguida, o estimador XGBoost que você construiu acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:10.681411Z",
     "iopub.status.busy": "2023-07-31T22:28:10.681105Z",
     "iopub.status.idle": "2023-07-31T22:28:11.223922Z",
     "shell.execute_reply": "2023-07-31T22:28:11.223192Z",
     "shell.execute_reply.started": "2023-07-31T22:28:10.681383Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "# Definição do pipeline de transformação e classificação\n",
    "pipeline = imbpipeline(steps = [['smote', ???], # Insira aqui o objeto SMOTE importado acima. Você pode fixar um random_state para ter resultados replicáveis.\n",
    "                                ['classifier', ??? ]]) # Insira aqui o estimador XGBoost criado acima.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas para classificação\n",
    "\n",
    "A figura abaixo apresenta algumas métricas de classificação binária, bem como os conceitos de TP, Tn, FP e FN.\n",
    "\n",
    "![image.png](https://miro.medium.com/v2/resize:fit:842/1*LVilqC3cy4AgyC1wD4RH-A.png)\n",
    "\n",
    "As métricas também sofrem com problema de desbalanceamento. Um caso clássico de problema de desbalancemento é da acurácia. Se não dermos o devido peso para as classes, facilmente atingimos patamares de 98% a 99%, pois o numero de TP, FP e FN fica negligenciável perto de TN.\n",
    "\n",
    "Outras métricas, como Precision e Recall, são bons aliados na nosso problema.\n",
    "\n",
    "- **Precision** (Precisão):\n",
    "\n",
    "    Precision é uma métrica que mede a proporção de instâncias classificadas como positivas (verdadeiras positivas) corretamente em relação ao total de instâncias classificadas como positivas (verdadeiras positivas + falsos positivos). Essa métrica é bastante útil quando o foco é reduzir os falsos positivos, ou seja, quando é crítico evitar a classificação errônea de exemplos negativos como positivos. Isso é especialmente relevante em problemas onde os falsos positivos podem ter consequências graves.\n",
    "\n",
    "- **Recall** (Sensibilidade ou True Positive Rate):\n",
    "\n",
    "    Recall mede a proporção de instâncias positivas corretamente classificadas (verdadeiros positivos) em relação ao total de instâncias verdadeiramente positivas (verdadeiros positivos + falsos negativos). Essa métrica é especialmente importante quando o objetivo é identificar corretamente todos os exemplos positivos, pois minimiza os falsos negativos. Isso é relevante em cenários onde a não detecção de exemplos positivos pode ter consequências negativas.\n",
    "\n",
    "O ideal é sempre ter o máximo de precisao na detecção da classe minoritária e sensibilidade quanto a identificação de toda essa classe. Uma forma de aliar as duas é utilizando a chamada métrica F1.\n",
    "\n",
    "- **F1 Score**:\n",
    "\n",
    "    O F1 Score é uma métrica que combina Precision e Recall para obter um equilíbrio entre elas. É a média harmônica entre as duas métricas.\n",
    "    \n",
    "    $$ F1_{Score} = 2 * \\frac{(Precision * Recall)}{(Precision + Recall)}$$\n",
    "    \n",
    "    O F1 Score é valioso em situações de desequilíbrio de classes, pois leva em conta tanto os falsos positivos quanto os falsos negativos. Isso faz com que seja uma métrica geralmente confiável para avaliar o desempenho do modelo em conjuntos de dados desbalanceados.\n",
    "\n",
    "\n",
    "\n",
    "- **ROC AUC**:\n",
    "\n",
    "    ![image.png](https://miro.medium.com/v2/resize:fit:722/1*pk05QGzoWhCgRiiFbz-oKQ.png)\n",
    "\n",
    "    O ROC AUC mede a capacidade do modelo de distinguir entre as classes, independentemente do ponto de corte de classificação escolhido. É uma métrica que leva em consideração tanto a taxa de verdadeiros positivos (recall) quanto a taxa de falsos positivos. Essa métrica é útil quando se deseja avaliar o desempenho global do modelo em diferentes pontos de corte de classificação e quando a proporção entre as classes não é o principal foco da avaliação.\n",
    "\n",
    "\n",
    "Aqui, temos a possibilidade de escolher qual utilizaremos. Em um panorama geral, se o desbalanceamento entre as classes for significativo e você estiver mais preocupado em ter um bom equilíbrio entre precisão e recall, o F1 Score pode ser mais adequado. Ele penaliza modelos que favorecem uma classe majoritária em detrimento da classe minoritária. Por outro lado, se você estiver interessado em uma visão mais geral da capacidade discriminativa do modelo e a proporção entre as classes não for o fator mais crítico para sua aplicação, o ROC AUC pode ser uma boa escolha.\n",
    "\n",
    "No final das contas, a escolha da métrica depende das necessidades e objetivos específicos do problema em questão. É sempre uma boa prática considerar várias métricas, incluindo o ROC AUC e o F1 Score, para obter uma visão mais completa do desempenho do modelo e tomar decisões informadas em relação aos resultados.\n",
    "\n",
    "Para o nosso propósito, escolheremos **ROC AUC** pois queremos descobrir, de forma geral, como podemos reduzir o problema do Churn e não necessariamente mitigar ponto a ponto dos clientes que serão churn. Porém, você também poderia aplicar o F1 score nesse caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Crie um objeto de Grid Search com Cross-validation usando o [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) do Sklearn, utilizando tudo que foi definido acima: pipeline, parameter grid, stratifiedKfold e utilizando a métrica 'roc_auc'para o scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:11.225805Z",
     "iopub.status.busy": "2023-07-31T22:28:11.224842Z",
     "iopub.status.idle": "2023-07-31T22:28:11.229942Z",
     "shell.execute_reply": "2023-07-31T22:28:11.228764Z",
     "shell.execute_reply.started": "2023-07-31T22:28:11.225781Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definição da estratégia de pesquisa de hiperparâmetros com gridsearch com a metrica ROC AUC\n",
    "grid_search = GridSearchCV(estimator=???, # Adicione aqui o pipeline. Se não houvesse pipeline, você adicionaria direto o estimador.\n",
    "                           param_grid=???, # Adicione o grid de parâmetros\n",
    "                           scoring=???, # Escolha a opção 'roc_auc' para o scoring\n",
    "                           cv=???, # Adicione a estratégia de validação cruzada definida acima\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: A hora do .fit()!!! Realize o .fit() do processo de grid search nos dados de treino\n",
    "Vá tomar um cafezinho enquanto aguarda..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:28:11.231260Z",
     "iopub.status.busy": "2023-07-31T22:28:11.230957Z",
     "iopub.status.idle": "2023-07-31T22:38:59.136937Z",
     "shell.execute_reply": "2023-07-31T22:38:59.136188Z",
     "shell.execute_reply.started": "2023-07-31T22:28:11.231237Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa:** Verifique qual foi o melhor score e os melhores parâmetros do seu modelo, fazendo o print dos atributos [*.best_score_*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=on%20allowed%20values.-,best_score_float,-Mean%20cross%2Dvalidated) e [*best_params_*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=is%20a%20function.-,best_params_dict,-Parameter%20setting%20that) do seu objeto de grid search criado e treinado acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.138668Z",
     "iopub.status.busy": "2023-07-31T22:38:59.138191Z",
     "iopub.status.idle": "2023-07-31T22:38:59.144539Z",
     "shell.execute_reply": "2023-07-31T22:38:59.143419Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.138635Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa:** Agora crie um objeto e atribua a ele o melhor modelo do seu grid_search usando [*.best_estimator_*](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=best_estimator_estimator)['classifier']\n",
    "\n",
    "Observação: é importante que você selecione apenas o \"classificador\" do best estimator, pois o SMOTE **NÃO** deve ser implementado em teste. Em alguns outros casos, você pode sim fazer uma sequência de préprocessamentos em um pipeline que façam sentido tanto para treino, quanto para teste, mas não nesse caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.146053Z",
     "iopub.status.busy": "2023-07-31T22:38:59.145754Z",
     "iopub.status.idle": "2023-07-31T22:38:59.158059Z",
     "shell.execute_reply": "2023-07-31T22:38:59.156618Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.146026Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Com esse modelo, faça um *.predict()* para obter as inferências dos seus dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.160574Z",
     "iopub.status.busy": "2023-07-31T22:38:59.159489Z",
     "iopub.status.idle": "2023-07-31T22:38:59.178168Z",
     "shell.execute_reply": "2023-07-31T22:38:59.177321Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.160532Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Utilize o [*classification_report*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) do Sklearn para verificar o f1-score, precision e recall por classe no **teste**, bem como acurácia total, vistas acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.179972Z",
     "iopub.status.busy": "2023-07-31T22:38:59.179497Z",
     "iopub.status.idle": "2023-07-31T22:38:59.196223Z",
     "shell.execute_reply": "2023-07-31T22:38:59.194959Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.179945Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Agora, utilize a função [*roc_auc_score*](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) do Sklearn para verificar o ROC AUC do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.206540Z",
     "iopub.status.busy": "2023-07-31T22:38:59.206231Z",
     "iopub.status.idle": "2023-07-31T22:38:59.214560Z",
     "shell.execute_reply": "2023-07-31T22:38:59.213405Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.206517Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Apresente a matriz de confusão utilizando a função [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) do Sklearn e utilize o [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html) do Seaborn para plotar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.216341Z",
     "iopub.status.busy": "2023-07-31T22:38:59.216026Z",
     "iopub.status.idle": "2023-07-31T22:38:59.431660Z",
     "shell.execute_reply": "2023-07-31T22:38:59.430696Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.216312Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que você infere de todas essas métricas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta:** Como aprimorar ainda mais os resultados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos drivers de churn\n",
    "\n",
    "Existem diversas maneiras de avaliar os principais *drivers* de churn para este caso ou das features com maior poder preditivo para o target em questão, de uma forma mais geral. Neste projeto, utilizaremos o conceito de **SHAP values**.\n",
    "\n",
    "### SHAP Values\n",
    "\n",
    "\n",
    "Shapley Values, comumente referidos como Shap Values, é um conceito derivado da teoria dos jogos que foi adaptado para a análise de modelos de machine learning. Essa técnica permite atribuir importância a cada feature (característica) em uma previsão específica feita por um modelo. Assim, o seu objetivo é trazer **explicabilidade** até para modelos mais complexos que, em princípio, seriam uma \"caixa-preta\" ininteligível.\n",
    "\n",
    "O objetivo dos Shap Values é entender como a contribuição de cada feature afeta a saída ou previsão do modelo para um exemplo de entrada em particular. Em outras palavras, eles quantificam o quanto cada feature contribuiu para a diferença entre o valor predito pelo modelo para um determinado exemplo e o valor médio de todas as previsões.\n",
    "\n",
    "Resumidamente, o conceito de Shap Values pode ser explicado da seguinte maneira:\n",
    "\n",
    "- Contexto do problema: Imagine que temos um modelo de machine learning treinado e queremos explicar a previsão do modelo para um exemplo específico.\n",
    "\n",
    "- Definição do Shap Value: O Shap Value para uma determinada feature em um exemplo de entrada é a contribuição média dessa feature para todas as possíveis combinações de features ao compará-la com o valor médio de todas as previsões.\n",
    "\n",
    "**Exemplo**: Na figura abaixo, foram calculados diversos valores SHAP, ou seja, o resultado do target \"y\" para vários valores de features, porém com a feature MedInc fixada nos diferentes pontos do eixo x:\n",
    "\n",
    "<img src=\"https://shap.readthedocs.io/en/latest/_images/example_notebooks_overviews_An_introduction_to_explainable_AI_with_Shapley_values_21_0.png\" alt=\"crossval\" width=\"40%\">\n",
    "\n",
    "Podemos, então, tirar uma média do valor de \"y\" para cada valor de x e isso vai nos dar uma ideia de como y se comporta quando x está naquele ponto. A diferença entre esse valor médio de x em cada ponto e o valor esperado de y em todos os casos (linha pontilhada horizontal cinza) é a contribuição de x para y.\n",
    "\n",
    "<img src=\"https://shap.readthedocs.io/en/latest/_images/example_notebooks_overviews_An_introduction_to_explainable_AI_with_Shapley_values_20_0.png\" alt=\"crossval\" width=\"40%\">\n",
    "\n",
    "\n",
    "- Importância individual de features: Os Shap Values permitem medir a importância individual de cada feature em relação à previsão do modelo. Eles representam o quanto cada feature contribuiu para a diferença entre a previsão específica e a média das previsões do modelo.\n",
    "\n",
    "- Propriedade de aditividade: Uma propriedade fundamental dos Shap Values é que eles são aditivos. Ou seja, a soma dos Shap Values de todas as features mais o valor médio das previsões do modelo é igual à previsão específica para o exemplo em questão.\n",
    "\n",
    "Essa abordagem de interpretação é particularmente útil para entender as decisões de modelos de machine learning complexos, como Gradient Boosting Machines e Redes Neurais, que normalmente são caixas-pretas e difíceis de explicar. Com os Shap Values, os cientistas de dados e os stakeholders podem ganhar insights sobre quais características estão mais influenciando as previsões e compreender como o modelo toma decisões para cada exemplo de entrada. Essa interpretação da performance do modelo é valiosa em muitos cenários, como em decisões críticas, explicabilidade de modelos em aplicações reais, detecção de viés e em conformidade com regulamentos, onde é necessário entender como as características individuais afetam as previsões do modelo\n",
    "\n",
    "[Biblioteca SHAP Values](https://shap.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Realize o plot do sumário da função de SHAP values uilizando [*shap.summary_plot()*](https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:38:59.433285Z",
     "iopub.status.busy": "2023-07-31T22:38:59.432913Z",
     "iopub.status.idle": "2023-07-31T22:39:27.306673Z",
     "shell.execute_reply": "2023-07-31T22:39:27.305449Z",
     "shell.execute_reply.started": "2023-07-31T22:38:59.433254Z"
    }
   },
   "outputs": [],
   "source": [
    "# A utilização da bica SHAP não é tão trivial. Por isso, vou deixar a configuração pronta para você fazer as modificações necessárias\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Tarefa: substitua seus dados de teste que você definiu acima pela variável x_test abaixo\n",
    "X_sample = pd.DataFrame(x_test, columns = encoded_df.drop(columns = [\"Churn Value\"]).columns.tolist()) \n",
    "\n",
    "# Calculo do Shapvalues isando TreeExplainer\n",
    "explainer = shap.TreeExplainer(\n",
    "    method['classifier'],\n",
    "    data = X_sample,\n",
    "    feature_perturbation=\"interventional\",\n",
    "    model_output=\"probability\",\n",
    ")\n",
    "shap_values = explainer(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:27.308883Z",
     "iopub.status.busy": "2023-07-31T22:39:27.308133Z",
     "iopub.status.idle": "2023-07-31T22:39:28.436076Z",
     "shell.execute_reply": "2023-07-31T22:39:28.435206Z",
     "shell.execute_reply.started": "2023-07-31T22:39:27.308855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualização do efeito médio das variáveis em ordem de prioridade para o modelo com summary_plot\n",
    "shap.summary_plot(shap_values, X_sample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:28.438639Z",
     "iopub.status.busy": "2023-07-31T22:39:28.437668Z",
     "iopub.status.idle": "2023-07-31T22:39:28.748042Z",
     "shell.execute_reply": "2023-07-31T22:39:28.747155Z",
     "shell.execute_reply.started": "2023-07-31T22:39:28.438603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualização do efeito médio das variáveis de forma absoluta com o plot em barras\n",
    "shap.summary_plot(shap_values, X_sample, plot_type='bar') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: O que você consegue enxergar nos gráficos acima? Quais variáveis tem mais poder de modificar a probabilidade de churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Visualize os shap_values para uma entrada individual qualquer (um número entre 0 e o tamanho máximo do seu dataset de teste)\n",
    "[Use a função shap.plots.waterfall](https://shap.readthedocs.io/en/latest/generated/shap.plots.waterfall.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:28.749797Z",
     "iopub.status.busy": "2023-07-31T22:39:28.749460Z",
     "iopub.status.idle": "2023-07-31T22:39:29.406218Z",
     "shell.execute_reply": "2023-07-31T22:39:29.405191Z",
     "shell.execute_reply.started": "2023-07-31T22:39:28.749766Z"
    }
   },
   "outputs": [],
   "source": [
    "# Um exemplo de como podemos ver o shap values para entradas individuais\n",
    "# Nesse caso, Tenure Month contribui com +21% na formação da probabilidade de churn, que nesse caso é 92.2%\n",
    "shap.plots.waterfall(shap_values[519])\n",
    "\n",
    "# Agora é sua vez: varie os valores de entrada para verificar o comportamento do modelo para várias samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos olhar um pouco como os valores se comportam para Tenure Month e Monthly Charges que sao nossas variáveis numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Utilize o [shap.plots.scatter](https://meet.google.com/cmw-irdy-ayu) para verificar como os valores se comportam no caso de features específicas, como Tenure Months e Monthly Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:29.409227Z",
     "iopub.status.busy": "2023-07-31T22:39:29.408340Z",
     "iopub.status.idle": "2023-07-31T22:39:29.722738Z",
     "shell.execute_reply": "2023-07-31T22:39:29.721423Z",
     "shell.execute_reply.started": "2023-07-31T22:39:29.409186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verifique como os valores se comportam para \"Tenure Months\"\n",
    "shap.plots.scatter(shap_values[:,\"Tenure Months\"], show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que verificamos nesse gráfico? Há tenure months mais ligados ao churn que outros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Faça o mesmo para Monthly Charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:29.724464Z",
     "iopub.status.busy": "2023-07-31T22:39:29.724089Z",
     "iopub.status.idle": "2023-07-31T22:39:30.007852Z",
     "shell.execute_reply": "2023-07-31T22:39:30.007192Z",
     "shell.execute_reply.started": "2023-07-31T22:39:29.724430Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: O que podemos inferir desse gráfico? Há valores de Monthly Charges mais ligados à probabilidade de churn que outros? O impacto é equivalente ao de Tenure Months?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a estratégia de retenção\n",
    "\n",
    "Agora que você analisou as influência das variáveis no churn, você precisa criar as possíveis estratégias para redução do churn e retenção dos clientes e **calcular o impacto potencial** de cada uma delas na redução de churn. Pontos importantes para essa análise:\n",
    "- Não se atenha apenas aos resultados da modelagem, mas considere também os insights que você tirou da **análise exploratória** que realizou lá em cima.\n",
    "- Para o cálculo do potencial de retenção de cada estratégia, você vai considerar que **todos os clientes aceitaram** a oferta proposta.\n",
    "\n",
    "\n",
    "Siga os seguintes passos para criar e testar suas hipóteses:\n",
    "\n",
    "- Escolha de duas a quatro variáveis que se mostraram relevantes para o churn e são **acionáveis**. Variáveis **acionáveis** são variáveis que permitem à empresa **tomar uma ação**. Por exemplo, se um tipo de contrato faz o cliente ter mais churn, a empresa pode realizar ofertas para alterar o contrato do cliente.\n",
    "- Crie um dataframe sintético para criar suas estratégias. Para isso, você deve **copiar** o dataframe de teste para esse novo dataframe.\n",
    "- Agora, para cada estratégia, **altere** esse dataframe sintético criado acima de acordo. Por exemplo, se você escolher fazer uma oferta para alterar o tipo de contrato, selecione as variáveis que serão afetadas e as altere, considerando como se **todos os clientes** a tenham aceitado.\n",
    "- O próximo passo consiste em dar esse dataset alterado como entrada do .predict() do seu modelo, da mesma forma que você fez para o dataset de teste lá em cima.\n",
    "- Agora, calcule a diferença percentual entre o número de clientes que deram churn no novo cenário e no antigo (utilize as predições anteriores do modelo para ter consistência)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pergunta**: Quais variáveis acionáveis você irá selecionar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Resposta**:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estratégia 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Copie o dataframe de teste para o primeiro dataframe sintético, relacionado à primeira estratéfia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:30.009308Z",
     "iopub.status.busy": "2023-07-31T22:39:30.008757Z",
     "iopub.status.idle": "2023-07-31T22:39:30.015984Z",
     "shell.execute_reply": "2023-07-31T22:39:30.014914Z",
     "shell.execute_reply.started": "2023-07-31T22:39:30.009283Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa:** Altere o dataset segundo a estratégia que você selecionou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:30.017453Z",
     "iopub.status.busy": "2023-07-31T22:39:30.017166Z",
     "iopub.status.idle": "2023-07-31T22:39:30.029290Z",
     "shell.execute_reply": "2023-07-31T22:39:30.028206Z",
     "shell.execute_reply.started": "2023-07-31T22:39:30.017431Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Utilize *.predict()* para prever os valores do churn para o novo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:30.030715Z",
     "iopub.status.busy": "2023-07-31T22:39:30.030468Z",
     "iopub.status.idle": "2023-07-31T22:39:30.045848Z",
     "shell.execute_reply": "2023-07-31T22:39:30.045188Z",
     "shell.execute_reply.started": "2023-07-31T22:39:30.030693Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Calcule a diferença percentual da quantidade de clientes que deram churn no caso inicial e nesse primeiro caso sintético."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-31T22:39:30.050119Z",
     "iopub.status.busy": "2023-07-31T22:39:30.046870Z",
     "iopub.status.idle": "2023-07-31T22:39:30.057527Z",
     "shell.execute_reply": "2023-07-31T22:39:30.056396Z",
     "shell.execute_reply.started": "2023-07-31T22:39:30.050074Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tarefa**: Faça isso para algumas estratégias e selecione a que lhe parecer mais viável em termos de % de retenção, mas também se a oferta lhe parece interessante para o cliente, pois estamos calculando o potencial caso todos os clientes aceitem e a retenção **real** vai depender dessa taxa de aceitação. Explique abaixo o que você aprendeu e suas considerações para a escolha da estratégia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "### Que estratégia você recomenda para o aumento da retenção e redução do churn?\n",
    "\n",
    "### Qual o potencial de redução de churn dessa estratégia, caso todos os clientes endereçados aceitem a oferta?\n",
    "\n",
    "### Que outros tipos de estratégias (menos mensuráveis) você acredita que poderiam funcionar (ex. estratégias de marketing)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
